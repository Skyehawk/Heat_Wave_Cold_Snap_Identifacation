{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "blessed-jacksonville",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: \u001b[91mUndefVarError: @using not defined\u001b[39m\nin expression starting at In[180]:8",
     "output_type": "error",
     "traceback": [
      "LoadError: \u001b[91mUndefVarError: @using not defined\u001b[39m\nin expression starting at In[180]:8",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      " [2] include_string(::Function, ::Module, ::String, ::String) at .\\loading.jl:1091"
     ]
    }
   ],
   "source": [
    "using Base\n",
    "using Dates\n",
    "using Missings\n",
    "using ShiftedArrays\n",
    "\n",
    "using BenchmarkTools\n",
    "using DataFrames\n",
    "@using DataFramesMeta\n",
    "using CSV\n",
    "using Glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "distinguished-walker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "find_files (generic function with 1 method)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function find_files(path, pattern, ext)\n",
    "    if isempty(pattern)\n",
    "        files=glob(\"**/*\"*ext, path) #Vector of filenames. Glob allows you to use the asterisk.\n",
    "        println(\"Number of files: \", length(files))    #Number of files to read.\n",
    "        return files\n",
    "    elseif !isempty(pattern)\n",
    "        files=glob(\"**/\"*pattern*ext, path) #Vector of filenames. Glob allows you to use the asterisk.\n",
    "        println(\"Number of files: \", length(files))    #Number of files to read.\n",
    "        return files\n",
    "    end\n",
    "    return []\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "funky-publicity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files: 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th><th>nunique</th><th>nmissing</th><th>eltype</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th><th>Union…</th><th>Union…</th><th>Type</th></tr></thead><tbody><p>8 rows × 8 columns</p><tr><th>1</th><td>WBANNO</td><td>4994.0</td><td>4994</td><td>4994.0</td><td>4994</td><td></td><td></td><td>Int64</td></tr><tr><th>2</th><td>UTC_DATE</td><td></td><td>20060101</td><td></td><td>20210302</td><td>5540</td><td></td><td>String</td></tr><tr><th>3</th><td>UTC_TIME</td><td></td><td>0000</td><td></td><td>2355</td><td>288</td><td></td><td>String</td></tr><tr><th>4</th><td>LST_DATE</td><td></td><td>20051231</td><td></td><td>20210302</td><td>5541</td><td></td><td>String</td></tr><tr><th>5</th><td>LST_TIME</td><td></td><td>0000</td><td></td><td>2355</td><td>288</td><td></td><td>String</td></tr><tr><th>6</th><td>LONGITUDE</td><td>-95.87</td><td>-95.87</td><td>-95.87</td><td>-95.87</td><td></td><td></td><td>Float64</td></tr><tr><th>7</th><td>LATITUDE</td><td>48.31</td><td>48.31</td><td>48.31</td><td>48.31</td><td></td><td></td><td>Float64</td></tr><tr><th>8</th><td>AIR_TEMPERATURE</td><td>3.61848</td><td>-42.0</td><td>4.4</td><td>36.0</td><td></td><td>3810</td><td>Union{Missing, Float64}</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccccc}\n",
       "\t& variable & mean & min & median & max & nunique & nmissing & eltype\\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & Union… & Union… & Type\\\\\n",
       "\t\\hline\n",
       "\t1 & WBANNO & 4994.0 & 4994 & 4994.0 & 4994 &  &  & Int64 \\\\\n",
       "\t2 & UTC\\_DATE &  & 20060101 &  & 20210302 & 5540 &  & String \\\\\n",
       "\t3 & UTC\\_TIME &  & 0000 &  & 2355 & 288 &  & String \\\\\n",
       "\t4 & LST\\_DATE &  & 20051231 &  & 20210302 & 5541 &  & String \\\\\n",
       "\t5 & LST\\_TIME &  & 0000 &  & 2355 & 288 &  & String \\\\\n",
       "\t6 & LONGITUDE & -95.87 & -95.87 & -95.87 & -95.87 &  &  & Float64 \\\\\n",
       "\t7 & LATITUDE & 48.31 & 48.31 & 48.31 & 48.31 &  &  & Float64 \\\\\n",
       "\t8 & AIR\\_TEMPERATURE & 3.61848 & -42.0 & 4.4 & 36.0 &  & 3810 & Union\\{Missing, Float64\\} \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "8×8 DataFrame. Omitted printing of 2 columns\n",
       "│ Row │ variable        │ mean    │ min      │ median │ max      │ nunique │\n",
       "│     │ \u001b[90mSymbol\u001b[39m          │ \u001b[90mUnion…\u001b[39m  │ \u001b[90mAny\u001b[39m      │ \u001b[90mUnion…\u001b[39m │ \u001b[90mAny\u001b[39m      │ \u001b[90mUnion…\u001b[39m  │\n",
       "├─────┼─────────────────┼─────────┼──────────┼────────┼──────────┼─────────┤\n",
       "│ 1   │ WBANNO          │ 4994.0  │ 4994     │ 4994.0 │ 4994     │         │\n",
       "│ 2   │ UTC_DATE        │         │ 20060101 │        │ 20210302 │ 5540    │\n",
       "│ 3   │ UTC_TIME        │         │ 0000     │        │ 2355     │ 288     │\n",
       "│ 4   │ LST_DATE        │         │ 20051231 │        │ 20210302 │ 5541    │\n",
       "│ 5   │ LST_TIME        │         │ 0000     │        │ 2355     │ 288     │\n",
       "│ 6   │ LONGITUDE       │ -95.87  │ -95.87   │ -95.87 │ -95.87   │         │\n",
       "│ 7   │ LATITUDE        │ 48.31   │ 48.31    │ 48.31  │ 48.31    │         │\n",
       "│ 8   │ AIR_TEMPERATURE │ 3.61848 │ -42.0    │ 4.4    │ 36.0     │         │"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_dir = \"D:/Libraries/Documents/Climatology_Personal/USCRN_USRCRN_SUBHOURLY/\"\n",
    "pattern = \"*-MN_Good*\"\n",
    "\n",
    "files = find_files(parent_dir,pattern,\".txt\")\n",
    "join_col= \"\"\n",
    "header_ = [\"WBANNO\", \"UTC_DATE\", \"UTC_TIME\", \"LST_DATE\", \"LST_TIME\", \"CRX_VN\", \"LONGITUDE\",\n",
    "    \"LATITUDE\", \"AIR_TEMPERATURE\", \"PRECIPITATION\", \"SOLAR_RADIATION\", \"SR_FLAG\",\n",
    "    \"SURFACE_TEMPERATURE\", \"ST_TYPE\", \"ST_FLAG\", \"RELATIVE_HUMIDITY\", \"RH_FLAG\",\n",
    "    \"SOIL_MOISTURE_5\", \"SOIL_TEMPERATURE_5\", \"WETNESS WET_FLAG\", \"WIND_1_5\", \"WIND_FLAG\"]\n",
    "types_ = [Int; fill(String, 5); fill(Float64, 5); String; Float64; fill(String,2);\n",
    "    Float64; String; fill(Float64,3); String; Float64; String]\n",
    "select_ = [\"WBANNO\",\"UTC_DATE\",\"UTC_TIME\",\"LST_DATE\",\"LST_TIME\",\"LONGITUDE\",\"LATITUDE\",\n",
    "    \"AIR_TEMPERATURE\"]\n",
    "missingstrings_ = [\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"-9999.0\",\"\",\"\",\"\",\"-9999.0\",\"\",\"\",\"\",\"\",\"\",\"-9999.0\",\"\",\"\",\"\"]\n",
    "temp_dfs=Vector{DataFrame}(undef, length(files)) #Create a vector of empty dataframes.\n",
    "for i in 1:length(files)\n",
    "    temp_dfs[i]=CSV.read(files[i],DataFrame,ignorerepeated=true,delim=' ',\n",
    "        header=header_,types=types_, select=select_, missingstrings=missingstrings_,\n",
    "        silencewarnings=true) #Read each  infileto its own dataframe.\n",
    "end\n",
    "\n",
    "df = reduce(vcat, temp_dfs)\n",
    "describe(df)\n",
    "\n",
    "#masterdf=join(temp_dfs..., kind = :cross, makeunique=false) #Join the temporary dataframes into one dataframe. \n",
    "#masterdf=outerjoin(tempdfs..., on=\"Column In Common\") #Join the temporary dataframes into one dataframe. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minimal-possibility",
   "metadata": {},
   "source": [
    "?CSV.read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-assessment",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "current-soviet",
   "metadata": {},
   "source": [
    "for (x,y) in enumerate(zip(eltype.(eachcol(df)),names(df)))\n",
    "    @show x, y\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "abandoned-password",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x, y) = (1, (Int64, \"WBANNO\"))\n",
      "(x, y) = (2, (Float64, \"LONGITUDE\"))\n",
      "(x, y) = (3, (Float64, \"LATITUDE\"))\n",
      "(x, y) = (4, (Float64, \"AIR_TEMPERATURE\"))\n",
      "(x, y) = (5, (DateTime, \"UTC_DATETIME\"))\n",
      "(x, y) = (6, (DateTime, \"LST_DATETIME\"))\n"
     ]
    }
   ],
   "source": [
    "dropmissing!(df::AbstractDataFrame, \"AIR_TEMPERATURE\")\n",
    "\n",
    "date_format = DateFormat(\"yyyymmdd HHMM\")\n",
    "df.UTC_DATETIME = DateTime.(df.UTC_DATE.*\" \".*df.UTC_TIME,date_format)\n",
    "df.LST_DATETIME = DateTime.(df.LST_DATE.*\" \".*df.LST_TIME,date_format)\n",
    "select!(df, Not([:UTC_DATE, :UTC_TIME, :LST_DATE, :LST_TIME]))\n",
    "\n",
    "for (x,y) in enumerate(zip(eltype.(eachcol(df)),names(df)))\n",
    "    @show x, y\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "technical-revolution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1591662-element Array{Union{Missing, Int64},1}:\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    0\n",
       "    ⋮\n",
       " 1207\n",
       " 1207\n",
       " 1207\n",
       " 1207\n",
       " 1207\n",
       " 1207\n",
       " 1207\n",
       " 1207\n",
       " 1207\n",
       " 1207\n",
       " 1207\n",
       " 1207"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_thresh = -30.\n",
    "df.THRESH_ORDINAL_RANK = sign.(df.AIR_TEMPERATURE.-temp_thresh)\n",
    "df.RUN_LENGTH = (df.THRESH_ORDINAL_RANK .- lag(df.THRESH_ORDINAL_RANK)).!= 0\n",
    "df.RUN_LENGTH[:1] = 0  #We set this to 0 due to the diff() fuction 1 line above, we do not know what occured t=-1 records ago\n",
    "df.RUN_LENGTH = cumsum(convert(Array{Union{Missing, Int64}}, df.RUN_LENGTH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "contrary-overhead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>UTC_BEGIN_DATETIME</th><th>UTC_END_DATETIME</th><th>UTC_DURATION</th><th>LST_BEGIN_DATETIME</th></tr><tr><th></th><th>DateTime</th><th>DateTime</th><th>Millise…</th><th>DateTime</th></tr></thead><tbody><p>1,208 rows × 9 columns (omitted printing of 5 columns)</p><tr><th>1</th><td>2006-01-01T00:05:00</td><td>2006-02-16T07:45:00</td><td>4023600000 milliseconds</td><td>2005-12-31T18:05:00</td></tr><tr><th>2</th><td>2006-02-16T07:50:00</td><td>2006-02-16T07:55:00</td><td>21900000 milliseconds</td><td>2006-02-16T01:50:00</td></tr><tr><th>3</th><td>2006-02-16T08:00:00</td><td>2006-02-16T08:00:00</td><td>21600000 milliseconds</td><td>2006-02-16T02:00:00</td></tr><tr><th>4</th><td>2006-02-16T08:05:00</td><td>2006-02-16T08:35:00</td><td>23400000 milliseconds</td><td>2006-02-16T02:05:00</td></tr><tr><th>5</th><td>2006-02-16T08:40:00</td><td>2006-02-16T08:50:00</td><td>22200000 milliseconds</td><td>2006-02-16T02:40:00</td></tr><tr><th>6</th><td>2006-02-16T08:55:00</td><td>2006-02-16T09:00:00</td><td>21900000 milliseconds</td><td>2006-02-16T02:55:00</td></tr><tr><th>7</th><td>2006-02-16T09:05:00</td><td>2006-02-16T09:15:00</td><td>22200000 milliseconds</td><td>2006-02-16T03:05:00</td></tr><tr><th>8</th><td>2006-02-16T09:20:00</td><td>2006-02-16T09:50:00</td><td>23400000 milliseconds</td><td>2006-02-16T03:20:00</td></tr><tr><th>9</th><td>2006-02-16T09:55:00</td><td>2006-02-16T10:10:00</td><td>22500000 milliseconds</td><td>2006-02-16T03:55:00</td></tr><tr><th>10</th><td>2006-02-16T10:15:00</td><td>2006-02-16T10:15:00</td><td>21600000 milliseconds</td><td>2006-02-16T04:15:00</td></tr><tr><th>11</th><td>2006-02-16T10:20:00</td><td>2006-02-16T11:05:00</td><td>24300000 milliseconds</td><td>2006-02-16T04:20:00</td></tr><tr><th>12</th><td>2006-02-16T11:10:00</td><td>2006-02-16T11:20:00</td><td>22200000 milliseconds</td><td>2006-02-16T05:10:00</td></tr><tr><th>13</th><td>2006-02-16T11:25:00</td><td>2006-02-16T11:25:00</td><td>21600000 milliseconds</td><td>2006-02-16T05:25:00</td></tr><tr><th>14</th><td>2006-02-16T11:30:00</td><td>2006-02-16T11:40:00</td><td>22200000 milliseconds</td><td>2006-02-16T05:30:00</td></tr><tr><th>15</th><td>2006-02-16T11:45:00</td><td>2006-02-16T12:25:00</td><td>24000000 milliseconds</td><td>2006-02-16T05:45:00</td></tr><tr><th>16</th><td>2006-02-16T12:30:00</td><td>2006-02-16T12:50:00</td><td>22800000 milliseconds</td><td>2006-02-16T06:30:00</td></tr><tr><th>17</th><td>2006-02-16T12:55:00</td><td>2006-02-16T12:55:00</td><td>21600000 milliseconds</td><td>2006-02-16T06:55:00</td></tr><tr><th>18</th><td>2006-02-16T13:00:00</td><td>2006-02-16T13:05:00</td><td>21900000 milliseconds</td><td>2006-02-16T07:00:00</td></tr><tr><th>19</th><td>2006-02-16T13:10:00</td><td>2006-02-17T08:30:00</td><td>91200000 milliseconds</td><td>2006-02-16T07:10:00</td></tr><tr><th>20</th><td>2006-02-17T08:35:00</td><td>2006-02-17T08:35:00</td><td>21600000 milliseconds</td><td>2006-02-17T02:35:00</td></tr><tr><th>21</th><td>2006-02-17T08:40:00</td><td>2006-02-17T17:15:00</td><td>52500000 milliseconds</td><td>2006-02-17T02:40:00</td></tr><tr><th>22</th><td>2006-02-17T17:20:00</td><td>2006-02-25T13:15:00</td><td>698100000 milliseconds</td><td>2006-02-17T11:20:00</td></tr><tr><th>23</th><td>2006-02-25T13:20:00</td><td>2006-02-25T13:20:00</td><td>21600000 milliseconds</td><td>2006-02-25T07:20:00</td></tr><tr><th>24</th><td>2006-02-25T13:25:00</td><td>2006-02-25T13:25:00</td><td>21600000 milliseconds</td><td>2006-02-25T07:25:00</td></tr><tr><th>25</th><td>2006-02-25T13:30:00</td><td>2006-02-25T13:35:00</td><td>21900000 milliseconds</td><td>2006-02-25T07:30:00</td></tr><tr><th>26</th><td>2006-02-25T13:40:00</td><td>2007-02-03T08:15:00</td><td>29637300000 milliseconds</td><td>2006-02-25T07:40:00</td></tr><tr><th>27</th><td>2007-02-03T08:20:00</td><td>2007-02-03T08:20:00</td><td>21600000 milliseconds</td><td>2007-02-03T02:20:00</td></tr><tr><th>28</th><td>2007-02-03T08:25:00</td><td>2007-02-03T15:55:00</td><td>48600000 milliseconds</td><td>2007-02-03T02:25:00</td></tr><tr><th>29</th><td>2007-02-03T16:00:00</td><td>2007-02-04T03:45:00</td><td>63900000 milliseconds</td><td>2007-02-03T10:00:00</td></tr><tr><th>30</th><td>2007-02-04T03:50:00</td><td>2007-02-04T03:50:00</td><td>21600000 milliseconds</td><td>2007-02-03T21:50:00</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& UTC\\_BEGIN\\_DATETIME & UTC\\_END\\_DATETIME & UTC\\_DURATION & LST\\_BEGIN\\_DATETIME & \\\\\n",
       "\t\\hline\n",
       "\t& DateTime & DateTime & Millise… & DateTime & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2006-01-01T00:05:00 & 2006-02-16T07:45:00 & 4023600000 milliseconds & 2005-12-31T18:05:00 & $\\dots$ \\\\\n",
       "\t2 & 2006-02-16T07:50:00 & 2006-02-16T07:55:00 & 21900000 milliseconds & 2006-02-16T01:50:00 & $\\dots$ \\\\\n",
       "\t3 & 2006-02-16T08:00:00 & 2006-02-16T08:00:00 & 21600000 milliseconds & 2006-02-16T02:00:00 & $\\dots$ \\\\\n",
       "\t4 & 2006-02-16T08:05:00 & 2006-02-16T08:35:00 & 23400000 milliseconds & 2006-02-16T02:05:00 & $\\dots$ \\\\\n",
       "\t5 & 2006-02-16T08:40:00 & 2006-02-16T08:50:00 & 22200000 milliseconds & 2006-02-16T02:40:00 & $\\dots$ \\\\\n",
       "\t6 & 2006-02-16T08:55:00 & 2006-02-16T09:00:00 & 21900000 milliseconds & 2006-02-16T02:55:00 & $\\dots$ \\\\\n",
       "\t7 & 2006-02-16T09:05:00 & 2006-02-16T09:15:00 & 22200000 milliseconds & 2006-02-16T03:05:00 & $\\dots$ \\\\\n",
       "\t8 & 2006-02-16T09:20:00 & 2006-02-16T09:50:00 & 23400000 milliseconds & 2006-02-16T03:20:00 & $\\dots$ \\\\\n",
       "\t9 & 2006-02-16T09:55:00 & 2006-02-16T10:10:00 & 22500000 milliseconds & 2006-02-16T03:55:00 & $\\dots$ \\\\\n",
       "\t10 & 2006-02-16T10:15:00 & 2006-02-16T10:15:00 & 21600000 milliseconds & 2006-02-16T04:15:00 & $\\dots$ \\\\\n",
       "\t11 & 2006-02-16T10:20:00 & 2006-02-16T11:05:00 & 24300000 milliseconds & 2006-02-16T04:20:00 & $\\dots$ \\\\\n",
       "\t12 & 2006-02-16T11:10:00 & 2006-02-16T11:20:00 & 22200000 milliseconds & 2006-02-16T05:10:00 & $\\dots$ \\\\\n",
       "\t13 & 2006-02-16T11:25:00 & 2006-02-16T11:25:00 & 21600000 milliseconds & 2006-02-16T05:25:00 & $\\dots$ \\\\\n",
       "\t14 & 2006-02-16T11:30:00 & 2006-02-16T11:40:00 & 22200000 milliseconds & 2006-02-16T05:30:00 & $\\dots$ \\\\\n",
       "\t15 & 2006-02-16T11:45:00 & 2006-02-16T12:25:00 & 24000000 milliseconds & 2006-02-16T05:45:00 & $\\dots$ \\\\\n",
       "\t16 & 2006-02-16T12:30:00 & 2006-02-16T12:50:00 & 22800000 milliseconds & 2006-02-16T06:30:00 & $\\dots$ \\\\\n",
       "\t17 & 2006-02-16T12:55:00 & 2006-02-16T12:55:00 & 21600000 milliseconds & 2006-02-16T06:55:00 & $\\dots$ \\\\\n",
       "\t18 & 2006-02-16T13:00:00 & 2006-02-16T13:05:00 & 21900000 milliseconds & 2006-02-16T07:00:00 & $\\dots$ \\\\\n",
       "\t19 & 2006-02-16T13:10:00 & 2006-02-17T08:30:00 & 91200000 milliseconds & 2006-02-16T07:10:00 & $\\dots$ \\\\\n",
       "\t20 & 2006-02-17T08:35:00 & 2006-02-17T08:35:00 & 21600000 milliseconds & 2006-02-17T02:35:00 & $\\dots$ \\\\\n",
       "\t21 & 2006-02-17T08:40:00 & 2006-02-17T17:15:00 & 52500000 milliseconds & 2006-02-17T02:40:00 & $\\dots$ \\\\\n",
       "\t22 & 2006-02-17T17:20:00 & 2006-02-25T13:15:00 & 698100000 milliseconds & 2006-02-17T11:20:00 & $\\dots$ \\\\\n",
       "\t23 & 2006-02-25T13:20:00 & 2006-02-25T13:20:00 & 21600000 milliseconds & 2006-02-25T07:20:00 & $\\dots$ \\\\\n",
       "\t24 & 2006-02-25T13:25:00 & 2006-02-25T13:25:00 & 21600000 milliseconds & 2006-02-25T07:25:00 & $\\dots$ \\\\\n",
       "\t25 & 2006-02-25T13:30:00 & 2006-02-25T13:35:00 & 21900000 milliseconds & 2006-02-25T07:30:00 & $\\dots$ \\\\\n",
       "\t26 & 2006-02-25T13:40:00 & 2007-02-03T08:15:00 & 29637300000 milliseconds & 2006-02-25T07:40:00 & $\\dots$ \\\\\n",
       "\t27 & 2007-02-03T08:20:00 & 2007-02-03T08:20:00 & 21600000 milliseconds & 2007-02-03T02:20:00 & $\\dots$ \\\\\n",
       "\t28 & 2007-02-03T08:25:00 & 2007-02-03T15:55:00 & 48600000 milliseconds & 2007-02-03T02:25:00 & $\\dots$ \\\\\n",
       "\t29 & 2007-02-03T16:00:00 & 2007-02-04T03:45:00 & 63900000 milliseconds & 2007-02-03T10:00:00 & $\\dots$ \\\\\n",
       "\t30 & 2007-02-04T03:50:00 & 2007-02-04T03:50:00 & 21600000 milliseconds & 2007-02-03T21:50:00 & $\\dots$ \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1208×9 DataFrame. Omitted printing of 6 columns\n",
       "│ Row  │ UTC_BEGIN_DATETIME  │ UTC_END_DATETIME    │ UTC_DURATION            │\n",
       "│      │ \u001b[90mDateTime\u001b[39m            │ \u001b[90mDateTime\u001b[39m            │ \u001b[90mMillisecond\u001b[39m             │\n",
       "├──────┼─────────────────────┼─────────────────────┼─────────────────────────┤\n",
       "│ 1    │ 2006-01-01T00:05:00 │ 2006-02-16T07:45:00 │ 4023600000 milliseconds │\n",
       "│ 2    │ 2006-02-16T07:50:00 │ 2006-02-16T07:55:00 │ 21900000 milliseconds   │\n",
       "│ 3    │ 2006-02-16T08:00:00 │ 2006-02-16T08:00:00 │ 21600000 milliseconds   │\n",
       "│ 4    │ 2006-02-16T08:05:00 │ 2006-02-16T08:35:00 │ 23400000 milliseconds   │\n",
       "│ 5    │ 2006-02-16T08:40:00 │ 2006-02-16T08:50:00 │ 22200000 milliseconds   │\n",
       "│ 6    │ 2006-02-16T08:55:00 │ 2006-02-16T09:00:00 │ 21900000 milliseconds   │\n",
       "│ 7    │ 2006-02-16T09:05:00 │ 2006-02-16T09:15:00 │ 22200000 milliseconds   │\n",
       "│ 8    │ 2006-02-16T09:20:00 │ 2006-02-16T09:50:00 │ 23400000 milliseconds   │\n",
       "│ 9    │ 2006-02-16T09:55:00 │ 2006-02-16T10:10:00 │ 22500000 milliseconds   │\n",
       "│ 10   │ 2006-02-16T10:15:00 │ 2006-02-16T10:15:00 │ 21600000 milliseconds   │\n",
       "⋮\n",
       "│ 1198 │ 2021-02-16T14:40:00 │ 2021-02-17T04:30:00 │ 71400000 milliseconds   │\n",
       "│ 1199 │ 2021-02-17T04:35:00 │ 2021-02-17T04:35:00 │ 21600000 milliseconds   │\n",
       "│ 1200 │ 2021-02-17T04:40:00 │ 2021-02-17T04:40:00 │ 21600000 milliseconds   │\n",
       "│ 1201 │ 2021-02-17T04:45:00 │ 2021-02-17T04:45:00 │ 21600000 milliseconds   │\n",
       "│ 1202 │ 2021-02-17T04:50:00 │ 2021-02-17T04:55:00 │ 21900000 milliseconds   │\n",
       "│ 1203 │ 2021-02-17T05:00:00 │ 2021-02-17T05:05:00 │ 21900000 milliseconds   │\n",
       "│ 1204 │ 2021-02-17T05:10:00 │ 2021-02-17T05:20:00 │ 22200000 milliseconds   │\n",
       "│ 1205 │ 2021-02-17T05:25:00 │ 2021-02-17T05:25:00 │ 21600000 milliseconds   │\n",
       "│ 1206 │ 2021-02-17T05:30:00 │ 2021-02-17T05:30:00 │ 21600000 milliseconds   │\n",
       "│ 1207 │ 2021-02-17T05:35:00 │ 2021-02-17T12:50:00 │ 47700000 milliseconds   │\n",
       "│ 1208 │ 2021-02-17T12:55:00 │ 2021-03-02T20:00:00 │ 1170300000 milliseconds │"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = groupby(df,:RUN_LENGTH)\n",
    "temp_dfs=Vector{DataFrame}(undef, length(gdf)) #Create a vector of empty dataframes.\n",
    "gdf[1]\n",
    "for i in 1:length(gdf)  \n",
    "    temp_dfs[i]= DataFrame(UTC_BEGIN_DATETIME = first(gdf[i].UTC_DATETIME),\n",
    "        UTC_END_DATETIME = last(gdf[i].UTC_DATETIME),\n",
    "        UTC_DURATION = last(gdf[i].UTC_DATETIME)- first(gdf[i].LST_DATETIME),\n",
    "        LST_BEGIN_DATETIME = first(gdf[i].LST_DATETIME),\n",
    "        LST_END_DATETIME = last(gdf[i].LST_DATETIME),\n",
    "        THRESH_ORDINAL_RANK = first(gdf[i].THRESH_ORDINAL_RANK),\n",
    "        MEAN_TEMP = mean(gdf[i].AIR_TEMPERATURE),\n",
    "        MAX_TEMP = maximum(gdf[i].AIR_TEMPERATURE),\n",
    "        MIN_TEMP = minimum(gdf[i].AIR_TEMPERATURE)\n",
    "\n",
    "    )\n",
    "end\n",
    "\n",
    "res = reduce(vcat, temp_dfs)\n",
    "#describe(df)\n",
    "\n",
    "#consecutive_group = [parent(gdf)[i, groupvars(gdf)] for i in gdf.starts]\n",
    "#res = DataFrame(MEAN_TEMPERATURE = mean.(consecutive_group.AIR_TEMPERATURE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "chubby-subject",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>variable</th><th>mean</th><th>min</th><th>median</th><th>max</th></tr><tr><th></th><th>Symbol</th><th>Union…</th><th>Any</th><th>Union…</th><th>Any</th></tr></thead><tbody><p>9 rows × 8 columns (omitted printing of 3 columns)</p><tr><th>1</th><td>UTC_BEGIN_DATETIME</td><td></td><td>2006-01-01T00:05:00</td><td></td><td>2021-02-17T12:55:00</td></tr><tr><th>2</th><td>UTC_END_DATETIME</td><td></td><td>2006-02-16T07:45:00</td><td></td><td>2021-03-02T20:00:00</td></tr><tr><th>3</th><td>UTC_DURATION</td><td></td><td>21600000 milliseconds</td><td></td><td>31788900000 milliseconds</td></tr><tr><th>4</th><td>LST_BEGIN_DATETIME</td><td></td><td>2005-12-31T18:05:00</td><td></td><td>2021-02-17T06:55:00</td></tr><tr><th>5</th><td>LST_END_DATETIME</td><td></td><td>2006-02-16T01:45:00</td><td></td><td>2021-03-02T14:00:00</td></tr><tr><th>6</th><td>THRESH_ORDINAL_RANK</td><td>0.00827815</td><td>-1.0</td><td>0.0</td><td>1.0</td></tr><tr><th>7</th><td>MEAN_TEMP</td><td>-28.6093</td><td>-36.4704</td><td>-30.0</td><td>9.03029</td></tr><tr><th>8</th><td>MAX_TEMP</td><td>-27.1237</td><td>-31.2</td><td>-30.0</td><td>36.0</td></tr><tr><th>9</th><td>MIN_TEMP</td><td>-30.4815</td><td>-42.0</td><td>-30.0</td><td>-28.7</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccccc}\n",
       "\t& variable & mean & min & median & max & \\\\\n",
       "\t\\hline\n",
       "\t& Symbol & Union… & Any & Union… & Any & \\\\\n",
       "\t\\hline\n",
       "\t1 & UTC\\_BEGIN\\_DATETIME &  & 2006-01-01T00:05:00 &  & 2021-02-17T12:55:00 & $\\dots$ \\\\\n",
       "\t2 & UTC\\_END\\_DATETIME &  & 2006-02-16T07:45:00 &  & 2021-03-02T20:00:00 & $\\dots$ \\\\\n",
       "\t3 & UTC\\_DURATION &  & 21600000 milliseconds &  & 31788900000 milliseconds & $\\dots$ \\\\\n",
       "\t4 & LST\\_BEGIN\\_DATETIME &  & 2005-12-31T18:05:00 &  & 2021-02-17T06:55:00 & $\\dots$ \\\\\n",
       "\t5 & LST\\_END\\_DATETIME &  & 2006-02-16T01:45:00 &  & 2021-03-02T14:00:00 & $\\dots$ \\\\\n",
       "\t6 & THRESH\\_ORDINAL\\_RANK & 0.00827815 & -1.0 & 0.0 & 1.0 & $\\dots$ \\\\\n",
       "\t7 & MEAN\\_TEMP & -28.6093 & -36.4704 & -30.0 & 9.03029 & $\\dots$ \\\\\n",
       "\t8 & MAX\\_TEMP & -27.1237 & -31.2 & -30.0 & 36.0 & $\\dots$ \\\\\n",
       "\t9 & MIN\\_TEMP & -30.4815 & -42.0 & -30.0 & -28.7 & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "9×8 DataFrame. Omitted printing of 4 columns\n",
       "│ Row │ variable            │ mean       │ min                   │ median │\n",
       "│     │ \u001b[90mSymbol\u001b[39m              │ \u001b[90mUnion…\u001b[39m     │ \u001b[90mAny\u001b[39m                   │ \u001b[90mUnion…\u001b[39m │\n",
       "├─────┼─────────────────────┼────────────┼───────────────────────┼────────┤\n",
       "│ 1   │ UTC_BEGIN_DATETIME  │            │ 2006-01-01T00:05:00   │        │\n",
       "│ 2   │ UTC_END_DATETIME    │            │ 2006-02-16T07:45:00   │        │\n",
       "│ 3   │ UTC_DURATION        │            │ 21600000 milliseconds │        │\n",
       "│ 4   │ LST_BEGIN_DATETIME  │            │ 2005-12-31T18:05:00   │        │\n",
       "│ 5   │ LST_END_DATETIME    │            │ 2006-02-16T01:45:00   │        │\n",
       "│ 6   │ THRESH_ORDINAL_RANK │ 0.00827815 │ -1.0                  │ 0.0    │\n",
       "│ 7   │ MEAN_TEMP           │ -28.6093   │ -36.4704              │ -30.0  │\n",
       "│ 8   │ MAX_TEMP            │ -27.1237   │ -31.2                 │ -30.0  │\n",
       "│ 9   │ MIN_TEMP            │ -30.4815   │ -42.0                 │ -30.0  │"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.RUN_LENGTH\n",
    "describe(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "robust-reform",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440×9 DataFrame\n",
      "│ Row │ UTC_BEGIN_DATETIME  │ UTC_END_DATETIME    │ UTC_DURATION           │\n",
      "│     │ \u001b[90mDateTime\u001b[39m            │ \u001b[90mDateTime\u001b[39m            │ \u001b[90mMillisecond\u001b[39m            │\n",
      "├─────┼─────────────────────┼─────────────────────┼────────────────────────┤\n",
      "│ 1   │ 2018-01-13T07:00:00 │ 2018-01-13T07:00:00 │ 21600000 milliseconds  │\n",
      "│ 2   │ 2009-02-03T12:20:00 │ 2009-02-03T12:20:00 │ 21600000 milliseconds  │\n",
      "│ 3   │ 2017-01-05T02:05:00 │ 2017-01-05T02:05:00 │ 21600000 milliseconds  │\n",
      "│ 4   │ 2019-02-09T02:25:00 │ 2019-02-09T02:25:00 │ 21600000 milliseconds  │\n",
      "│ 5   │ 2007-12-14T10:55:00 │ 2007-12-14T10:55:00 │ 21600000 milliseconds  │\n",
      "│ 6   │ 2020-01-11T03:40:00 │ 2020-01-11T03:40:00 │ 21600000 milliseconds  │\n",
      "│ 7   │ 2011-01-03T03:55:00 │ 2011-01-03T03:55:00 │ 21600000 milliseconds  │\n",
      "│ 8   │ 2016-02-13T06:35:00 │ 2016-02-13T06:35:00 │ 21600000 milliseconds  │\n",
      "│ 9   │ 2017-01-05T04:25:00 │ 2017-01-05T04:25:00 │ 21600000 milliseconds  │\n",
      "│ 10  │ 2017-12-27T03:45:00 │ 2017-12-27T03:45:00 │ 21600000 milliseconds  │\n",
      "⋮\n",
      "│ 430 │ 2009-01-13T03:40:00 │ 2009-01-13T16:55:00 │ 69300000 milliseconds  │\n",
      "│ 431 │ 2007-02-05T01:30:00 │ 2007-02-05T15:05:00 │ 70500000 milliseconds  │\n",
      "│ 432 │ 2014-01-02T02:00:00 │ 2014-01-02T15:50:00 │ 71400000 milliseconds  │\n",
      "│ 433 │ 2008-02-11T00:25:00 │ 2008-02-11T14:15:00 │ 71400000 milliseconds  │\n",
      "│ 434 │ 2021-02-14T01:15:00 │ 2021-02-14T15:15:00 │ 72000000 milliseconds  │\n",
      "│ 435 │ 2010-01-02T00:50:00 │ 2010-01-02T15:45:00 │ 75300000 milliseconds  │\n",
      "│ 436 │ 2009-01-15T23:10:00 │ 2009-01-16T14:25:00 │ 76500000 milliseconds  │\n",
      "│ 437 │ 2009-01-14T23:45:00 │ 2009-01-15T15:40:00 │ 78900000 milliseconds  │\n",
      "│ 438 │ 2017-12-30T22:40:00 │ 2017-12-31T15:55:00 │ 83700000 milliseconds  │\n",
      "│ 439 │ 2014-01-05T21:35:00 │ 2014-01-06T17:45:00 │ 94200000 milliseconds  │\n",
      "│ 440 │ 2019-01-29T10:55:00 │ 2019-01-31T16:10:00 │ 213300000 milliseconds │\n",
      "\n",
      "│ Row │ LST_BEGIN_DATETIME  │ LST_END_DATETIME    │ THRESH_ORDINAL_RANK │\n",
      "│     │ \u001b[90mDateTime\u001b[39m            │ \u001b[90mDateTime\u001b[39m            │ \u001b[90mFloat64\u001b[39m             │\n",
      "├─────┼─────────────────────┼─────────────────────┼─────────────────────┤\n",
      "│ 1   │ 2018-01-13T01:00:00 │ 2018-01-13T01:00:00 │ -1.0                │\n",
      "│ 2   │ 2009-02-03T06:20:00 │ 2009-02-03T06:20:00 │ -1.0                │\n",
      "│ 3   │ 2017-01-04T20:05:00 │ 2017-01-04T20:05:00 │ -1.0                │\n",
      "│ 4   │ 2019-02-08T20:25:00 │ 2019-02-08T20:25:00 │ -1.0                │\n",
      "│ 5   │ 2007-12-14T04:55:00 │ 2007-12-14T04:55:00 │ -1.0                │\n",
      "│ 6   │ 2020-01-10T21:40:00 │ 2020-01-10T21:40:00 │ -1.0                │\n",
      "│ 7   │ 2011-01-02T21:55:00 │ 2011-01-02T21:55:00 │ -1.0                │\n",
      "│ 8   │ 2016-02-13T00:35:00 │ 2016-02-13T00:35:00 │ -1.0                │\n",
      "│ 9   │ 2017-01-04T22:25:00 │ 2017-01-04T22:25:00 │ -1.0                │\n",
      "│ 10  │ 2017-12-26T21:45:00 │ 2017-12-26T21:45:00 │ -1.0                │\n",
      "⋮\n",
      "│ 430 │ 2009-01-12T21:40:00 │ 2009-01-13T10:55:00 │ -1.0                │\n",
      "│ 431 │ 2007-02-04T19:30:00 │ 2007-02-05T09:05:00 │ -1.0                │\n",
      "│ 432 │ 2014-01-01T20:00:00 │ 2014-01-02T09:50:00 │ -1.0                │\n",
      "│ 433 │ 2008-02-10T18:25:00 │ 2008-02-11T08:15:00 │ -1.0                │\n",
      "│ 434 │ 2021-02-13T19:15:00 │ 2021-02-14T09:15:00 │ -1.0                │\n",
      "│ 435 │ 2010-01-01T18:50:00 │ 2010-01-02T09:45:00 │ -1.0                │\n",
      "│ 436 │ 2009-01-15T17:10:00 │ 2009-01-16T08:25:00 │ -1.0                │\n",
      "│ 437 │ 2009-01-14T17:45:00 │ 2009-01-15T09:40:00 │ -1.0                │\n",
      "│ 438 │ 2017-12-30T16:40:00 │ 2017-12-31T09:55:00 │ -1.0                │\n",
      "│ 439 │ 2014-01-05T15:35:00 │ 2014-01-06T11:45:00 │ -1.0                │\n",
      "│ 440 │ 2019-01-29T04:55:00 │ 2019-01-31T10:10:00 │ -1.0                │\n",
      "\n",
      "│ Row │ MEAN_TEMP │ MAX_TEMP │ MIN_TEMP │\n",
      "│     │ \u001b[90mFloat64\u001b[39m   │ \u001b[90mFloat64\u001b[39m  │ \u001b[90mFloat64\u001b[39m  │\n",
      "├─────┼───────────┼──────────┼──────────┤\n",
      "│ 1   │ -30.9     │ -30.9    │ -30.9    │\n",
      "│ 2   │ -30.8     │ -30.8    │ -30.8    │\n",
      "│ 3   │ -30.8     │ -30.8    │ -30.8    │\n",
      "│ 4   │ -30.8     │ -30.8    │ -30.8    │\n",
      "│ 5   │ -30.7     │ -30.7    │ -30.7    │\n",
      "│ 6   │ -30.6     │ -30.6    │ -30.6    │\n",
      "│ 7   │ -30.5     │ -30.5    │ -30.5    │\n",
      "│ 8   │ -30.5     │ -30.5    │ -30.5    │\n",
      "│ 9   │ -30.5     │ -30.5    │ -30.5    │\n",
      "│ 10  │ -30.5     │ -30.5    │ -30.5    │\n",
      "⋮\n",
      "│ 430 │ -35.8381  │ -30.3    │ -41.4    │\n",
      "│ 431 │ -33.8829  │ -30.2    │ -36.6    │\n",
      "│ 432 │ -36.272   │ -30.3    │ -40.2    │\n",
      "│ 433 │ -32.9497  │ -30.1    │ -36.0    │\n",
      "│ 434 │ -32.8231  │ -30.1    │ -36.6    │\n",
      "│ 435 │ -35.2083  │ -30.2    │ -39.4    │\n",
      "│ 436 │ -32.5924  │ -30.2    │ -35.0    │\n",
      "│ 437 │ -32.1328  │ -30.1    │ -33.8    │\n",
      "│ 438 │ -32.6452  │ -30.1    │ -37.0    │\n",
      "│ 439 │ -31.5062  │ -30.1    │ -32.8    │\n",
      "│ 440 │ -35.1311  │ -30.1    │ -42.0    │"
     ]
    }
   ],
   "source": [
    "#@where(res, :THRESH_ORDINAL_RANK .== -1)\n",
    "show(sort!(res[res[:,:THRESH_ORDINAL_RANK] .== -1, :], [:UTC_DURATION, :MEAN_TEMP]), true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-recognition",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
